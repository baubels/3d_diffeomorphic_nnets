{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6cbffb-4b10-4d14-a9fe-e9b0085fb040",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d75e2e-54ea-4241-8c3c-911b94331750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T21:01:30.093107Z",
     "iopub.status.busy": "2022-08-09T21:01:30.092140Z",
     "iopub.status.idle": "2022-08-09T21:01:38.095770Z",
     "shell.execute_reply": "2022-08-09T21:01:38.094896Z",
     "shell.execute_reply.started": "2022-08-09T21:01:30.092902Z"
    },
    "id": "27d75e2e-54ea-4241-8c3c-911b94331750",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import pymeshlab\n",
    "import polyscope as ps\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fe114-15dc-4c29-a200-88ec9ab4b388",
   "metadata": {
    "id": "246fe114-15dc-4c29-a200-88ec9ab4b388"
   },
   "source": [
    "#### Diffeomorphic registrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e165cf-e01f-419c-8aa9-3eecabc5db86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### feed in SCHREC19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3406d0-7976-4190-abca-41b121841f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T22:47:20.577121Z",
     "iopub.status.busy": "2022-08-09T22:47:20.576419Z",
     "iopub.status.idle": "2022-08-09T22:47:20.595697Z",
     "shell.execute_reply": "2022-08-09T22:47:20.594213Z",
     "shell.execute_reply.started": "2022-08-09T22:47:20.577085Z"
    },
    "id": "0b3406d0-7976-4190-abca-41b121841f8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) get starting .obj and ending .obj as numpy arrays\n",
    "# 2) feed into net\n",
    "# 3) visually reconstruct object using polyscope, reconstructing normals and meshes using open3d\n",
    "\n",
    "# 1 - feeding correctly formatted data into the neural net. This is optimised to the SCHREC19 dataset.\n",
    "def convert_obj_to_numpy(obj):\n",
    "    ms = pymeshlab.MeshSet()\n",
    "    ms.load_new_mesh(obj)\n",
    "    m = ms.current_mesh()\n",
    "    v_matrix = m.vertex_matrix()\n",
    "    return v_matrix\n",
    "\n",
    "def collect_source_and_target(sourcefile, targetfile):\n",
    "    source_shape  = convert_obj_to_numpy(sourcefile)\n",
    "    target_shape  = convert_obj_to_numpy(targetfile)\n",
    "\n",
    "    source_shape = source_shape.reshape((source_shape.shape[0], 1, 3))\n",
    "    target_shape = target_shape.reshape((target_shape.shape[0], 1, 3))\n",
    "\n",
    "    source_scaling = np.max(source_shape)\n",
    "    source_bias    = np.min(source_shape)\n",
    "    source_shape   = (source_shape - np.min(source_shape))/np.max(source_shape)\n",
    "    source_shape   = (source_shape - np.min(source_shape))/np.max(source_shape)\n",
    "\n",
    "\n",
    "    target_scaling = np.max(target_shape)\n",
    "    target_bias    = np.min(target_shape)\n",
    "    target_shape   = (target_shape - np.min(target_shape))/np.max(target_shape)\n",
    "    target_shape   = (target_shape - np.min(target_shape))/np.max(target_shape)\n",
    "\n",
    "    source_shape = tf.convert_to_tensor(source_shape)\n",
    "    target_shape = tf.convert_to_tensor(target_shape)\n",
    "    \n",
    "    return source_shape, target_shape\n",
    "\n",
    "# source_shape, target_shape = collect_source_and_target('scan_015.obj', 'scan_016.obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e08edd-282a-40eb-bf64-6df32ea84a68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### initialise and train diffeomorphic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f216a366-9af2-4ad2-881e-3fdda7a2e21e",
   "metadata": {
    "id": "f216a366-9af2-4ad2-881e-3fdda7a2e21e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2 - initialising the diffeomorphic net\n",
    "\n",
    "width = 800\n",
    "batch_size=source_shape.shape[0]\n",
    "\n",
    "class DenseEulerFBlock(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DenseEulerFBlock, self).__init__()\n",
    "        self.initialiser = tf.keras.initializers.GlorotUniform()\n",
    "        \n",
    "        self.d1 = tf.keras.layers.Dense(width, activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(width, activation=None)\n",
    "        self.d3 = tf.keras.layers.Dense(3, activation=None, use_bias=False)\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        return self.d3(self.d2(self.d1(input_tensor)))\n",
    "\n",
    "\n",
    "class DenseEulerMergeBlock(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DenseEulerMergeBlock, self).__init__()\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        return tf.nn.relu(input_tensor)\n",
    "\n",
    "\n",
    "def cd_so(y_pred, y_true):\n",
    "    cd1 =  tf.math.reduce_sum(tf.math.sqrt(\n",
    "           tf.math.reduce_min(tf.math.reduce_sum(\n",
    "           tf.math.square(tf.reshape(y_pred, (batch_size, 1, 1, 3)) - y_true), axis=-1), axis=1)))\n",
    "    cd2 =  tf.math.reduce_sum(tf.math.sqrt(\n",
    "           tf.math.reduce_min(tf.math.reduce_sum(\n",
    "           tf.math.square(tf.reshape(y_true, (batch_size, 1, 1, 3)) - y_pred), axis=-1), axis=1)))\n",
    "    return cd1 + cd2\n",
    "\n",
    "\n",
    "def DenseCombinedCDLoss(d1, d2, d3, d4, d5, d6, m6, truth, sigma=0.1):\n",
    "    regularisation_loss = 0.5*(tf.norm(d1) + tf.norm(d2) + tf.norm(d3) + tf.norm(d4) + tf.norm(d5) + tf.norm(d6))/6\n",
    "    data_term = 0.5*cd_so(m6, truth)/(sigma**2)\n",
    "    return data_term + regularisation_loss\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "input0 = tf.keras.Input(shape=(1, 3))\n",
    "\n",
    "d1 = DenseEulerFBlock()(input0)\n",
    "m1 = DenseEulerMergeBlock()(input0 + d1)\n",
    "\n",
    "d2 = DenseEulerFBlock()(m1)\n",
    "m2 = DenseEulerMergeBlock()(m1 + d2)\n",
    "\n",
    "d3 = DenseEulerFBlock()(m2)\n",
    "m3 = DenseEulerMergeBlock()(m2 + d3)\n",
    "\n",
    "d4 = DenseEulerFBlock()(m3)\n",
    "m4 = DenseEulerMergeBlock()(m3 + d4)\n",
    "\n",
    "d5 = DenseEulerFBlock()(m4)\n",
    "m5 = DenseEulerMergeBlock()(m4 + d5)\n",
    "\n",
    "d6 = DenseEulerFBlock()(m5)\n",
    "m6 = DenseEulerMergeBlock()(m5 + d6)\n",
    "\n",
    "\n",
    "true0 = tf.keras.Input(shape=(1, 3))\n",
    "model = tf.keras.Model([input0, true0], [input0, m1, m2, m3, m4, m5, m6, true0])\n",
    "model.add_loss(DenseCombinedCDLoss(d1, d2, d3, d4, d5, d6, m6, true0, sigma=0.1)) # hoping this works? (I haven't done EMD or chamfer's distance)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-6,beta_1=0.9,beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer=opt, loss=None)\n",
    "\n",
    "# 2 - running the net\n",
    "batch_size=source_shape.shape[0]\n",
    "model.fit(x=[source_shape, target_shape], y=None, epochs=1000, verbose=1, batch_size=batch_size);\n",
    "plt.plot(model.history.history['loss']);\n",
    "print(model.history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce9073-66a7-43d6-80d2-6bc15bec6d5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### reconstruct flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0e29ec-9d50-4d21-8e4e-906ac8c99083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T22:58:52.689186Z",
     "iopub.status.busy": "2022-08-09T22:58:52.688889Z",
     "iopub.status.idle": "2022-08-09T22:58:52.703031Z",
     "shell.execute_reply": "2022-08-09T22:58:52.702019Z",
     "shell.execute_reply.started": "2022-08-09T22:58:52.689156Z"
    },
    "id": "6f0e29ec-9d50-4d21-8e4e-906ac8c99083",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3 - construction\n",
    "\n",
    "def reconstruct_numpy_to_points_and_vertices(np_arr):\n",
    "    ms = pymeshlab.Mesh(np_arr)\n",
    "    ms.generate_surface_reconstruction_ball_pivoting()\n",
    "    m = ms.current_mesh()\n",
    "    v_matrix = m.vertex_matrix()\n",
    "    f_matrix = m.face_matrix()\n",
    "    return [v_matrix, f_matrix]\n",
    "\n",
    "\n",
    "def make_pointed_flow(model, source_shape, target_shape, separator=50):\n",
    "    prediction = model.predict([source_shape, target_shape])\n",
    "    prediction[0] = prediction[0].reshape((prediction[0].shape[0], 3))\n",
    "    full_flow = np.copy(prediction[0]*100)\n",
    "    for i in range(1, len(prediction)):\n",
    "        prediction[i] = prediction[i].reshape((prediction[i].shape[0], 3))\n",
    "        full_flow = np.append(full_flow, prediction[i]*100 + i*separator*np.array([1, 0, 0]), axis=0)\n",
    "    return full_flow\n",
    "\n",
    "\n",
    "# recommended...\n",
    "# saving the diffeomorphism for huge reductions in stress\n",
    "\n",
    "# np.save('full_flow', visualise_flow(model, source_shape, target_shape))\n",
    "# point_cloud = np.load('full_flow.npy')\n",
    "\n",
    "\n",
    "# point_cloud = np.load('full_flow.npy')\n",
    "def visualise_flow(flow_array, pts_per_obj=None, view_style='turntable', mesh_type='ball', mesh=True):\n",
    "    ps.init()\n",
    "    ps.set_navigation_style(view_style)\n",
    "    if mesh is not True:\n",
    "        # visualise non-meshed flow (just a point-cloud)  \n",
    "        ps.register_point_cloud(\"pointed_flow\", point_cloud)\n",
    "\n",
    "    elif mesh is True:\n",
    "        if pts_per_obj is None:\n",
    "            raise ValueError(\"As you are meshing, you need to specify `pts_per_obj`. Generally this is flow_array.shape[0]/(resnet_lddmm timesteps + 2)\")\n",
    "            \n",
    "        for i in range(flow_array.shape[0]//pts_per_obj):\n",
    "            # visualising it meshed\n",
    "            obj = flow_array[pts_per_obj*i:pts_per_obj*(i+1)]\n",
    "\n",
    "            # import points into the open3d 03d object\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(obj)\n",
    "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=5, max_nn=100)) # estimates normals for the point cloud\n",
    "            \n",
    "            if mesh_type == 'ball':\n",
    "                radius = np.mean(pcd.compute_nearest_neighbor_distance())\n",
    "                meshes = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(pcd,o3d.utility.DoubleVector([radius, radius]))\n",
    "            \n",
    "            elif mesh_type == 'poisson':\n",
    "                # computes the smooth poisson mesh of the point cloud\n",
    "                meshes = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=11, width=0, scale=1.5, linear_fit=True)[0]\n",
    "            \n",
    "            elif mesh_type == 'alpha':\n",
    "                alpha_val = 0.1 # adjust as necessary\n",
    "                meshes = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha_val)\n",
    "\n",
    "            # write mesh to .obj file, which will then be viewed by pymeshlab and then polyscope\n",
    "            o3d.io.write_triangle_mesh(\"full_flow_meshed_pivoted\" + \"{}\".format(i) + \".obj\", meshes)\n",
    "\n",
    "            # create pymeshlab object that will then have states and properties stored\n",
    "            ms = pymeshlab.MeshSet()\n",
    "            ms.load_new_mesh('full_flow_meshed_pivoted' + '{}'.format(i) + '.obj')\n",
    "            m = ms.current_mesh()\n",
    "\n",
    "            # get numpy arrays of vertices and faces of the current mesh\n",
    "            v_matrix = m.vertex_matrix()\n",
    "            f_matrix = m.face_matrix()\n",
    "\n",
    "\n",
    "            # visualise with polyscope\n",
    "            # a=ps.register_point_cloud(\"full_flow_rasterised {}\".format(i), v_matrix)\n",
    "            b=ps.register_surface_mesh(\"full_flow_meshed {}\".format(i), v_matrix, f_matrix, smooth_shade=True)\n",
    "            b.set_back_face_policy('identical')\n",
    "    ps.show()\n",
    "\n",
    "# visualise_meshed_flow(point_cloud, 1001)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "meshed_diffeo3d_chamfer_yescolab.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
